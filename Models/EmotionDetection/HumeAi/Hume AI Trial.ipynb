{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d1e5fd4-b956-421a-89de-1a5d7c6b7802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hume\n",
      "  Downloading hume-0.6.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting httpx<0.28.0,>=0.27.0 (from httpx[http2]<0.28.0,>=0.27.0->hume)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting pydantic<3.0.0,>=2.6.4 (from hume)\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "     ---------------------------------------- 0.0/125.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/125.2 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/125.2 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/125.2 kB ? eta -:--:--\n",
      "     ------------ ------------------------ 41.0/125.2 kB 245.8 kB/s eta 0:00:01\n",
      "     -------------------------------- --- 112.6/125.2 kB 595.3 kB/s eta 0:00:01\n",
      "     ------------------------------------ 125.2/125.2 kB 566.2 kB/s eta 0:00:00\n",
      "Collecting pydub<0.26.0,>=0.25.1 (from hume)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.3.0 in c:\\users\\kevin\\.conda\\envs\\myenv\\lib\\site-packages (from hume) (4.9.0)\n",
      "Requirement already satisfied: websockets<13.0,>=12.0 in c:\\users\\kevin\\.conda\\envs\\myenv\\lib\\site-packages (from hume) (12.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\kevin\\.conda\\envs\\myenv\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->httpx[http2]<0.28.0,>=0.27.0->hume) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\kevin\\.conda\\envs\\myenv\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->httpx[http2]<0.28.0,>=0.27.0->hume) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<0.28.0,>=0.27.0->httpx[http2]<0.28.0,>=0.27.0->hume)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\kevin\\.conda\\envs\\myenv\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->httpx[http2]<0.28.0,>=0.27.0->hume) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kevin\\.conda\\envs\\myenv\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->httpx[http2]<0.28.0,>=0.27.0->hume) (1.3.0)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.28.0,>=0.27.0->httpx[http2]<0.28.0,>=0.27.0->hume)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting h2<5,>=3 (from httpx[http2]<0.28.0,>=0.27.0->hume)\n",
      "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3.0.0,>=2.6.4->hume)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic<3.0.0,>=2.6.4->hume)\n",
      "  Downloading pydantic_core-2.20.1-cp312-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]<0.28.0,>=0.27.0->hume)\n",
      "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]<0.28.0,>=0.27.0->hume)\n",
      "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading hume-0.6.0-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.8/45.8 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.6/75.6 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "   ---------------------------------------- 0.0/77.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 77.9/77.9 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "   ---------------------------------------- 0.0/423.9 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 286.7/423.9 kB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 423.9/423.9 kB 5.3 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.20.1-cp312-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.9 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 6.0 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/1.9 MB 5.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/1.9 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.4/1.9 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.6/1.9 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.7/1.9 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.5/57.5 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.3/58.3 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: pydub, pydantic-core, hyperframe, hpack, h11, annotated-types, pydantic, httpcore, h2, httpx, hume\n",
      "Successfully installed annotated-types-0.7.0 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.5 httpx-0.27.0 hume-0.6.0 hyperframe-6.0.1 pydantic-2.8.2 pydantic-core-2.20.1 pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install hume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5799faf1-5f61-4d4d-b796-c9aabdabfd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUME_API_KEY = 'lQcg62KN7ErQGx7uK7EdRyv2cA8UZGTEpFQY2wfQJc22DxkO'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50c43ea-ce4b-4a39-b342-f27ad492ae7b",
   "metadata": {},
   "source": [
    "## Hume api ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e126ed36-c1a5-4b56-90c0-55cf8d41ae43",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HumeBatchClient' object has no attribute 'get_job_status'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m job_id \u001b[38;5;241m=\u001b[39m job\u001b[38;5;241m.\u001b[39mid\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# Get job status\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     status \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_job_status(job_id)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msucceeded\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;66;03m# Job succeeded, get the predictions\u001b[39;00m\n\u001b[0;32m     31\u001b[0m         result \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_predictions(job_id)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HumeBatchClient' object has no attribute 'get_job_status'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from hume import HumeBatchClient\n",
    "from hume.models.config import FaceConfig\n",
    "import tempfile\n",
    "\n",
    "# Replace with your Hume API key\n",
    "api_key = os.getenv(\"HUME_API_KEY\", HUME_API_KEY)\n",
    "\n",
    "# Initialize Hume AI client\n",
    "client = HumeBatchClient(api_key)\n",
    "\n",
    "# Load image file\n",
    "image_path = 'images/kevin_happy.jpg'\n",
    "with open(image_path, 'rb') as image_file:\n",
    "    image_bytes = image_file.read()\n",
    "\n",
    "# Create a temporary file to store the image bytes\n",
    "with tempfile.NamedTemporaryFile(delete=False, suffix=\".jpg\") as temp_image_file:\n",
    "    temp_image_file.write(image_bytes)\n",
    "    temp_image_file_path = temp_image_file.name\n",
    "\n",
    "# Ensure the file is closed before it's passed to the API\n",
    "try:\n",
    "    # Configure the request for facial emotion recognition\n",
    "    config = FaceConfig()\n",
    "\n",
    "    # Send the request with the image file path\n",
    "    job = client.submit_job(urls=None, files=[temp_image_file_path], configs=[config])\n",
    "\n",
    "    # Wait for the result (this can take a few seconds)\n",
    "    result = job.get_predictions()\n",
    "\n",
    "    print(result)\n",
    "    # Process the results\n",
    "    # for face in result['faces']:\n",
    "    #     emotions = face['emotions']\n",
    "    #     for emotion in emotions:\n",
    "    #         print(f\"Emotion: {emotion['name']}, Score: {emotion['score']}\")\n",
    "finally:\n",
    "    # Clean up the temporary file\n",
    "    os.remove(temp_image_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89bef2a-fdec-4e33-8cd4-65097a93f75e",
   "metadata": {},
   "source": [
    "## Hume AI Github Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9fe02303-3ec7-4752-ab44-a06881e2c9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 expressed emotions are between timestamp 0 and 12 : \n",
      "Joy\n",
      "Amusement\n",
      "Interest\n",
      "Calmness\n",
      "Excitement\n",
      "The emotions that peaked over 0.7 : \n"
     ]
    }
   ],
   "source": [
    "from hume import HumeBatchClient\n",
    "from hume.models.config import FaceConfig, ProsodyConfig\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Initialize the Hume client with your API key\n",
    "client = HumeBatchClient(HUME_API_KEY)\n",
    "\n",
    "# Path to your local image file\n",
    "image_path = 'images/kevin_happy.jpg'\n",
    "\n",
    "# Submit a job with the local image file\n",
    "job = client.submit_job(urls=None, files=[image_path], configs=[FaceConfig(), ProsodyConfig()])\n",
    "job_id = job.id;\n",
    "\n",
    "# Await job completion\n",
    "job = job.await_complete()\n",
    "\n",
    "# Get the job predictions\n",
    "job_predictions = client.get_job_predictions(job_id=job_id)\n",
    "\n",
    "# The start and end time range of predictions to be processed\n",
    "start_time = 0\n",
    "end_time = 12\n",
    "\n",
    "# Top n emotions\n",
    "n_top_values = 5\n",
    "\n",
    "# A threshold of what is defined as a peaked emotion\n",
    "peak_threshold = 0.7\n",
    "\n",
    "emotions_dict = dict()\n",
    "peaked_emotions_w_score_time_dict = dict()\n",
    "\n",
    "# Process the predictions for facial expressions\n",
    "for file in job_predictions:\n",
    "    for prediction in file['results']['predictions']:\n",
    "        for grouped_prediction in prediction['models']['face']['grouped_predictions']:\n",
    "            for grouped_prediction_prediction in grouped_prediction['predictions']:\n",
    "                if grouped_prediction_prediction['time'] >= start_time and grouped_prediction_prediction['time'] <= end_time:\n",
    "                    for emotion in grouped_prediction_prediction['emotions']:\n",
    "                        if emotion['name'] not in emotions_dict:\n",
    "                            emotions_dict[emotion['name']] = emotion['score']\n",
    "                        else:\n",
    "                            emotions_dict[emotion['name']] += emotion['score']\n",
    "                        if emotion['score'] >= peak_threshold:\n",
    "                            peaked_emotions_w_score_time_dict[emotion['name']] = (emotion['score'], grouped_prediction_prediction['time'])\n",
    "\n",
    "# Calculate average emotion scores\n",
    "emotions_average = {emotion: score / len(emotions_dict) for emotion, score in emotions_dict.items()}\n",
    "\n",
    "# Sort emotions by average score in descending order\n",
    "ascend_sorted_emotion_average = sorted(emotions_average, key=emotions_average.get, reverse=True)\n",
    "\n",
    "# Output the top emotions\n",
    "print(f'The top {n_top_values} expressed emotions are between timestamp {start_time} and {end_time} : ')\n",
    "for i in range(n_top_values):\n",
    "    print(ascend_sorted_emotion_average[i])\n",
    "\n",
    "# Output emotions that peaked over the threshold\n",
    "print(f'The emotions that peaked over {peak_threshold} : ')\n",
    "for peaked_emotions, (score, time) in peaked_emotions_w_score_time_dict.items():\n",
    "    print(f\"{peaked_emotions} with score of {score} at {time}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9eaf2cc4-9097-4b16-be4b-9279a8331ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hume import HumeBatchClient\n",
    "from hume.models.config import FaceConfig, ProsodyConfig\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Initialize the Hume client with your API key\n",
    "client = HumeBatchClient(HUME_API_KEY)\n",
    "\n",
    "# Path to your local image file\n",
    "def find_emotion(imgUrl):\n",
    "    image_path = imgUrl\n",
    "    \n",
    "    # Submit a job with the local image file\n",
    "    job = client.submit_job(urls=None, files=[image_path], configs=[FaceConfig(), ProsodyConfig()])\n",
    "    job_id = job.id;\n",
    "    \n",
    "    # Await job completion\n",
    "    job = job.await_complete()\n",
    "    \n",
    "    # Get the job predictions\n",
    "    job_predictions = client.get_job_predictions(job_id=job_id)\n",
    "    \n",
    "    # The start and end time range of predictions to be processed\n",
    "    start_time = 0\n",
    "    end_time = 12\n",
    "    \n",
    "    # Top n emotions\n",
    "    n_top_values = 5\n",
    "    \n",
    "    # A threshold of what is defined as a peaked emotion\n",
    "    peak_threshold = 0.7\n",
    "    \n",
    "    emotions_dict = dict()\n",
    "    peaked_emotions_w_score_time_dict = dict()\n",
    "    \n",
    "    # Process the predictions for facial expressions\n",
    "    for file in job_predictions:\n",
    "        for prediction in file['results']['predictions']:\n",
    "            for grouped_prediction in prediction['models']['face']['grouped_predictions']:\n",
    "                for grouped_prediction_prediction in grouped_prediction['predictions']:\n",
    "                    if grouped_prediction_prediction['time'] >= start_time and grouped_prediction_prediction['time'] <= end_time:\n",
    "                        for emotion in grouped_prediction_prediction['emotions']:\n",
    "                            if emotion['name'] not in emotions_dict:\n",
    "                                emotions_dict[emotion['name']] = emotion['score']\n",
    "                            else:\n",
    "                                emotions_dict[emotion['name']] += emotion['score']\n",
    "                            if emotion['score'] >= peak_threshold:\n",
    "                                peaked_emotions_w_score_time_dict[emotion['name']] = (emotion['score'], grouped_prediction_prediction['time'])\n",
    "    \n",
    "    # Calculate average emotion scores\n",
    "    emotions_average = {emotion: score / len(emotions_dict) for emotion, score in emotions_dict.items()}\n",
    "    \n",
    "    # Sort emotions by average score in descending order\n",
    "    ascend_sorted_emotion_average = sorted(emotions_average, key=emotions_average.get, reverse=True)\n",
    "    \n",
    "    # Output the top emotions\n",
    "    print(f'The top {n_top_values} expressed emotions are between timestamp {start_time} and {end_time} : ')\n",
    "    for i in range(n_top_values):\n",
    "        print(ascend_sorted_emotion_average[i])\n",
    "    \n",
    "    # Output emotions that peaked over the threshold\n",
    "    print(f'The emotions that peaked over {peak_threshold} : ')\n",
    "    for peaked_emotions, (score, time) in peaked_emotions_w_score_time_dict.items():\n",
    "        print(f\"{peaked_emotions} with score of {score} at {time}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b121584e-4ebf-4438-9b69-79e4b4c7a296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 expressed emotions are between timestamp 0 and 12 : \n",
      "Calmness\n",
      "Boredom\n",
      "Concentration\n",
      "Confusion\n",
      "Tiredness\n",
      "The emotions that peaked over 0.7 : \n",
      "Boredom with score of 0.7193500399589539 at 0.0\n",
      "Calmness with score of 0.7618798017501831 at 0.0\n"
     ]
    }
   ],
   "source": [
    "find_emotion('images/monil2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c706d2f-0d06-4b31-80ce-aecb05ea7676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 expressed emotions are between timestamp 0 and 12 : \n",
      "Confusion\n",
      "Disappointment\n",
      "Boredom\n",
      "Anger\n",
      "Surprise (negative)\n",
      "The emotions that peaked over 0.7 : \n"
     ]
    }
   ],
   "source": [
    "find_emotion('images/monil3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a537bd9-37dd-45b1-924e-d0dbc4745141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
